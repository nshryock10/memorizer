{"ast":null,"code":"var _jsxFileName = \"/Users/nickshryock/Documents/WebDevProjects/memorizer/src/Components/Practice.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef, useEffect } from \"react\";\nimport PracticeCard from \"./PracticeCard\";\nimport { Link } from \"react-router-dom\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport './Practice.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction Practice() {\n  _s();\n  const [phase, setPhase] = useState('before'); //options are before, during, after\n  const [inputType, setInputType] = useState(null); //options are mic or keyboard\n  const [speechSupported, setSpeechSupported] = useState(true);\n  const [textInput, setTextInput] = useState('');\n  const [editVoice, setEditVoice] = useState(false);\n  const [answer, setAnswer] = useState('');\n  const microphoneRef = useRef(null);\n  const {\n    transcript,\n    resetTranscript\n  } = useSpeechRecognition();\n  const transcriptRef = useRef(transcript);\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    setSpeechSupported(false);\n  }\n  const handleListening = () => {\n    SpeechRecognition.startListening({\n      continuous: true\n    });\n  };\n  const stopHandle = () => {\n    SpeechRecognition.stopListening();\n  };\n  const handleReset = () => {\n    stopHandle();\n    resetTranscript();\n    setTextInput('');\n  };\n  const handleTextChange = () => {};\n  const handleFinish = () => {\n    //trigger PUT request\n    console.log(answer);\n  };\n  useEffect(() => {\n    if (textInput) {\n      setPhase('after');\n      setAnswer(textInput);\n    } else {\n      setPhase('before');\n      setAnswer(textInput);\n    }\n  }, [textInput]);\n\n  //Review this block for use for editing voice dictation -------------- //\n  useEffect(() => {\n    console.log(transcriptRef.current);\n    transcriptRef.current = transcript;\n    setAnswer(transcript);\n  }, [transcript]);\n\n  // -------------------------------------------------------------------- //\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"practice-container\",\n    children: /*#__PURE__*/_jsxDEV(PracticeCard, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 74,\n      columnNumber: 9\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 73,\n    columnNumber: 5\n  }, this);\n}\n_s(Practice, \"gG0E3WqKWFtMhSmZsUmVATQpTeQ=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = Practice;\nexport default Practice;\nvar _c;\n$RefreshReg$(_c, \"Practice\");","map":{"version":3,"names":["React","useState","useRef","useEffect","PracticeCard","Link","SpeechRecognition","useSpeechRecognition","jsxDEV","_jsxDEV","Practice","_s","phase","setPhase","inputType","setInputType","speechSupported","setSpeechSupported","textInput","setTextInput","editVoice","setEditVoice","answer","setAnswer","microphoneRef","transcript","resetTranscript","transcriptRef","browserSupportsSpeechRecognition","handleListening","startListening","continuous","stopHandle","stopListening","handleReset","handleTextChange","handleFinish","console","log","current","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/nickshryock/Documents/WebDevProjects/memorizer/src/Components/Practice.js"],"sourcesContent":["import React, { useState, useRef, useEffect } from \"react\";\nimport PracticeCard from \"./PracticeCard\";\nimport { Link } from \"react-router-dom\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport './Practice.css';\n\nfunction Practice() {\n\n    const [phase, setPhase] = useState('before') //options are before, during, after\n    const [inputType, setInputType] = useState(null); //options are mic or keyboard\n    const [speechSupported, setSpeechSupported] = useState(true);\n    const [textInput, setTextInput] = useState('');\n    const [editVoice, setEditVoice] = useState(false);\n    const [answer, setAnswer] = useState('');\n    const microphoneRef = useRef(null);\n    const { transcript, resetTranscript } = useSpeechRecognition();\n\n    const transcriptRef = useRef(transcript);\n    \n    if(!SpeechRecognition.browserSupportsSpeechRecognition()){\n        setSpeechSupported(false)\n    }\n    \n    const handleListening = () => {\n        SpeechRecognition.startListening({\n            continuous: true,\n        })\n    };\n\n    const stopHandle = () => {\n        SpeechRecognition.stopListening();\n    }\n\n    const handleReset = () => {\n        stopHandle();\n        resetTranscript();\n        setTextInput('')\n    }\n\n    const handleTextChange = () => {\n\n    }\n\n    const handleFinish = () => {\n        //trigger PUT request\n        console.log(answer)\n    }\n\n    useEffect(() => {\n        if(textInput){\n            setPhase('after')\n            setAnswer(textInput)\n        }else{\n            setPhase('before')\n            setAnswer(textInput)\n        }\n        \n    }, [textInput])\n\n    //Review this block for use for editing voice dictation -------------- //\n    useEffect(() => {\n        \n            console.log(transcriptRef.current)\n            transcriptRef.current = transcript\n            setAnswer(transcript)\n        \n    }, [transcript])\n\n    // -------------------------------------------------------------------- //\n\n\n  return (\n    <div className=\"practice-container\">\n        <PracticeCard />\n    </div>\n  );\n}\n\nexport default Practice;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAC1D,OAAOC,YAAY,MAAM,gBAAgB;AACzC,SAASC,IAAI,QAAQ,kBAAkB;AACvC,OAAOC,iBAAiB,IAAIC,oBAAoB,QAAQ,0BAA0B;AAClF,OAAO,gBAAgB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAExB,SAASC,QAAQA,CAAA,EAAG;EAAAC,EAAA;EAEhB,MAAM,CAACC,KAAK,EAAEC,QAAQ,CAAC,GAAGZ,QAAQ,CAAC,QAAQ,CAAC,EAAC;EAC7C,MAAM,CAACa,SAAS,EAAEC,YAAY,CAAC,GAAGd,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;EAClD,MAAM,CAACe,eAAe,EAAEC,kBAAkB,CAAC,GAAGhB,QAAQ,CAAC,IAAI,CAAC;EAC5D,MAAM,CAACiB,SAAS,EAAEC,YAAY,CAAC,GAAGlB,QAAQ,CAAC,EAAE,CAAC;EAC9C,MAAM,CAACmB,SAAS,EAAEC,YAAY,CAAC,GAAGpB,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACqB,MAAM,EAAEC,SAAS,CAAC,GAAGtB,QAAQ,CAAC,EAAE,CAAC;EACxC,MAAMuB,aAAa,GAAGtB,MAAM,CAAC,IAAI,CAAC;EAClC,MAAM;IAAEuB,UAAU;IAAEC;EAAgB,CAAC,GAAGnB,oBAAoB,CAAC,CAAC;EAE9D,MAAMoB,aAAa,GAAGzB,MAAM,CAACuB,UAAU,CAAC;EAExC,IAAG,CAACnB,iBAAiB,CAACsB,gCAAgC,CAAC,CAAC,EAAC;IACrDX,kBAAkB,CAAC,KAAK,CAAC;EAC7B;EAEA,MAAMY,eAAe,GAAGA,CAAA,KAAM;IAC1BvB,iBAAiB,CAACwB,cAAc,CAAC;MAC7BC,UAAU,EAAE;IAChB,CAAC,CAAC;EACN,CAAC;EAED,MAAMC,UAAU,GAAGA,CAAA,KAAM;IACrB1B,iBAAiB,CAAC2B,aAAa,CAAC,CAAC;EACrC,CAAC;EAED,MAAMC,WAAW,GAAGA,CAAA,KAAM;IACtBF,UAAU,CAAC,CAAC;IACZN,eAAe,CAAC,CAAC;IACjBP,YAAY,CAAC,EAAE,CAAC;EACpB,CAAC;EAED,MAAMgB,gBAAgB,GAAGA,CAAA,KAAM,CAE/B,CAAC;EAED,MAAMC,YAAY,GAAGA,CAAA,KAAM;IACvB;IACAC,OAAO,CAACC,GAAG,CAAChB,MAAM,CAAC;EACvB,CAAC;EAEDnB,SAAS,CAAC,MAAM;IACZ,IAAGe,SAAS,EAAC;MACTL,QAAQ,CAAC,OAAO,CAAC;MACjBU,SAAS,CAACL,SAAS,CAAC;IACxB,CAAC,MAAI;MACDL,QAAQ,CAAC,QAAQ,CAAC;MAClBU,SAAS,CAACL,SAAS,CAAC;IACxB;EAEJ,CAAC,EAAE,CAACA,SAAS,CAAC,CAAC;;EAEf;EACAf,SAAS,CAAC,MAAM;IAERkC,OAAO,CAACC,GAAG,CAACX,aAAa,CAACY,OAAO,CAAC;IAClCZ,aAAa,CAACY,OAAO,GAAGd,UAAU;IAClCF,SAAS,CAACE,UAAU,CAAC;EAE7B,CAAC,EAAE,CAACA,UAAU,CAAC,CAAC;;EAEhB;;EAGF,oBACEhB,OAAA;IAAK+B,SAAS,EAAC,oBAAoB;IAAAC,QAAA,eAC/BhC,OAAA,CAACL,YAAY;MAAAsC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACf,CAAC;AAEV;AAAClC,EAAA,CAtEQD,QAAQ;EAAA,QAS2BH,oBAAoB;AAAA;AAAAuC,EAAA,GATvDpC,QAAQ;AAwEjB,eAAeA,QAAQ;AAAC,IAAAoC,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}